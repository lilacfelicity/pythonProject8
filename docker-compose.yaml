version: '3.8'

networks:
  medical_network:
    driver: bridge

volumes:
  postgres_data:
  postgres_airflow_data:
  redis_data:
  grafana_data:
  airflow_dags:
  airflow_logs:
  airflow_plugins:

services:
  # Nginx reverse proxy
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    container_name: nginx
    ports:
      - "80:80"
    depends_on:
      - backend
      - frontend
      - grafana
#      - airflow-webserver
    restart: unless-stopped
    networks:
      - medical_network


  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD:-medical_password}
      POSTGRES_USER: ${DB_USER:-medical_user}
      POSTGRES_DB: ${DB_NAME:-medical_db}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    expose:
      - "5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-medical_user}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - medical_network


  redis:
    image: redis:7-alpine
    container_name: redis
    expose:
      - "6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - medical_network


  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: medical_backend
    expose:
      - "8045"
    environment:
      - DB_USER=${DB_USER:-medical_user}
      - DB_PASSWORD=${DB_PASSWORD:-medical_password}
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-medical_db}
      - REDIS_URL=redis://redis:6379
      - SECRET_KEY=${SECRET_KEY:-medical_secret_key_2024}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://0.0.0.0:8045/api/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - medical_network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: medical_frontend
    environment:
      - VITE_API_URL=http://192.168.31.137
      - VITE_WS_URL=ws://192.168.31.137/ws
      - VITE_GRAFANA_URL=/192.168.31.137
    expose:
      - "3000"
    volumes:
      # Маунтим исходники для hot reload
      - ./frontend/src:/app/src
      - ./frontend/package.json:/app/package.json
      - ./frontend/vite.config.js:/app/vite.config.js
      - ./frontend/tailwind.config.js:/app/tailwind.config.js
      - ./frontend/postcss.config.js:/app/postcss.config.js
      - ./.env:/app/.env
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - medical_network

  iot-simulator:
    build:
      context: ./iot-simulator
      dockerfile: Dockerfile
    container_name: iot_simulator
    volumes:
      # Маунтим исходники для hot reload
      - ./simulator.py:/simulator.py
    environment:
      - API_URL=http://nginx/api
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - medical_network



  grafana:
    image: grafana/grafana:10.2.0
    container_name: grafana
    expose:
      - "3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/grafana/dashboards  # Mount to match dashboards.yml path
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini  # Mount custom config
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_DATABASE_TYPE=postgres
      - GF_DATABASE_HOST=postgres:5432
      - GF_DATABASE_NAME=${DB_NAME:-medical_db}
      - GF_DATABASE_USER=${DB_USER:-medical_user}
      - GF_DATABASE_PASSWORD=${DB_PASSWORD:-medical_password}
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - medical_network

  # PostgreSQL for Airflow
#  postgres-airflow:
#    image: postgres:15-alpine
#    container_name: postgres_airflow
#    environment:
#      POSTGRES_PASSWORD: airflow_password
#      POSTGRES_USER: airflow_user
#      POSTGRES_DB: airflow_db
#    volumes:
#      - postgres_airflow_data:/var/lib/postgresql/data
#    expose:
#      - "5432"
#    healthcheck:
#      test: ["CMD-SHELL", "pg_isready -U airflow_user"]
#      interval: 10s
#      timeout: 5s
#      retries: 5
#    restart: unless-stopped
#    networks:
#      - medical_network
#
#  # Airflow init
#  airflow-init:
#    image: apache/airflow:2.7.3
#    container_name: airflow_init
#    environment:
#      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow_user:airflow_password@postgres-airflow:5432/airflow_db
#      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-U7uFQm0jJ_XpD0OWMxP8BNwfvCXPHgI9qwXhARtNTmg=}
#      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#      - AIRFLOW__WEBSERVER__BASE_URL=http://localhost/airflow
#      - _AIRFLOW_DB_UPGRADE=true
#      - _AIRFLOW_WWW_USER_CREATE=true
#      - _AIRFLOW_WWW_USER_USERNAME=admin
#      - _AIRFLOW_WWW_USER_PASSWORD=admin
#    volumes:
#      - ./airflow/dags:/opt/airflow/dags
#    depends_on:
#      postgres-airflow:
#        condition: service_healthy
#    entrypoint: /bin/bash
#    command: >
#      -c "airflow db init &&
#          airflow users create --username admin --firstname Admin --lastname Admin --role Admin --email admin@example.com --password admin || true &&
#          airflow connections add medical_postgres --conn-type postgres --conn-host postgres --conn-schema ${DB_NAME:-medical_db} --conn-login ${DB_USER:-medical_user} --conn-password ${DB_PASSWORD:-medical_password} || true"
#    restart: "no"
#    networks:
#      - medical_network
#
#  # Airflow webserver
#  airflow-webserver:
#    image: apache/airflow:2.7.3
#    container_name: airflow_webserver
#    expose:
#      - "8080"
#    environment:
#      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow_user:airflow_password@postgres-airflow:5432/airflow_db
#      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-U7uFQm0jJ_XpD0OWMxP8BNwfvCXPHgI9qwXhARtNTmg=}
#      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#      - AIRFLOW__WEBSERVER__BASE_URL=http://localhost/airflow
#    volumes:
#      - ./airflow/dags:/opt/airflow/dags
#      - airflow_logs:/opt/airflow/logs
#    depends_on:
#      airflow-init:
#        condition: service_completed_successfully
#    command: airflow webserver
#    healthcheck:
#      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
#      interval: 30s
#      timeout: 10s
#      retries: 3
#    restart: always
#    networks:
#      - medical_network
#
#  # Airflow scheduler
#  airflow-scheduler:
#    image: apache/airflow:2.7.3
#    container_name: airflow_scheduler
#    environment:
#      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow_user:airflow_password@postgres-airflow:5432/airflow_db
#      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-U7uFQm0jJ_XpD0OWMxP8BNwfvCXPHgI9qwXhARtNTmg=}
#      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#    volumes:
#      - ./airflow/dags:/opt/airflow/dags
#      - airflow_logs:/opt/airflow/logs
#    depends_on:
#      airflow-init:
#        condition: service_completed_successfully
#    command: airflow scheduler
#    restart: always
#    networks:
#      - medical_network